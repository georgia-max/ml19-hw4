"""Functions for fitting Gaussian mixture models"""
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import multivariate_normal


def gmm(data, num_clusters, plot=False):
    """
    Compute the cluster probabilities, means, and covariances of a Gaussian mixture model
    :param data: d x n matrix of n d-dimensional data points
    :type data: ndarray
    :param num_clusters: number of Gaussians to fit
    :type num_clusters: int
    :param plot: mode for plotting two-dimensional data. Can be False (no plotting), 'iter' (plot every iteration), or
    'final' (plot the final Gaussians).
    :return: tuple of (means, sigma, probs), where means is a d x num_clusters matrix, sigma is a list of num_clusters
    matrices of size d by d, and probs is a length-k vector of cluster-membership probabilities
    :rtype: tuple
    """
    d, n = data.shape
    print("For this set of data:")
    print("d (dimension) is", d)
    print("n (data points) is", n)
    print("num_clusters is", num_clusters)

    # initialize clusters

    mu = np.mean(data, 1)
    centered_data = data - mu.reshape([-1, 1])
    full_sigma = np.inner(centered_data, centered_data) / n

    means = sample_gaussian(mu, full_sigma, num_clusters)

    sigmas = []

    for i in range(num_clusters):
        sigmas.append(np.eye(d))

    probs = np.ones(num_clusters) / num_clusters

    # start outer loop

    max_iters = 1000
    tolerance = 1e-4        # For convergence checking

    prev_probs = 0

    # add this to covariance matrices to prevent them from getting too skinny
    reg = 1e-4 * np.eye(d)

    for i in range(max_iters):
        print("=======starting iteration=======", i)
        membership_log = compute_membership_probs(data, means, sigmas, probs)
        membership = np.exp(membership_log)

        ###################################################################
        # Insert your code to update cluster prior, means, and covariances
        # (probs, means, sigmas)
        ###################################################################
        # Compute probs in log space
        probs = np.exp(logsumexp(membership_log, dim=1)) / n
        #print("probs\n", probs, probs.shape)

        # Compute mean in regular (non-log) space
        means_numerator = np.matmul(data, membership.T)
        means_denominator = np.sum(membership.T, axis=0).reshape((1,num_clusters))
        means = np.divide(means_numerator, means_denominator)
        #print("means\n", means.shape)

        # Compute Covariance in regular (non-log) space

        for i in range (0, num_clusters):
            data_sub_mean = np.subtract(data, means[:,i].reshape(d, 1))    # (d, n)
            #print("data_sub_mean", data_sub_mean.shape)
            sigmas_numerator = np.multiply(membership[i,:], data_sub_mean).dot(data_sub_mean.T)
            sigmas_i = np.divide(sigmas_numerator, means_denominator[0,i])
            sigmas.append(sigmas_i)
        ##################################################################
        # End of code to compute probs, means, and sigma
        ##################################################################

        # plot GMM

        if d == 2 and plot is 'iter':
            plot_gmm(data, means, sigmas, probs)
            plt.pause(1.0 / 30.0)
            plt.clf()

        # check for convergence

        change = np.linalg.norm(prev_probs - probs)
        prev_probs = probs
        if change < tolerance:
            break

    if d == 2 and plot is 'final' or plot is 'iter':
        plot_gmm(data, means, sigmas, probs)

    return means, sigmas, probs


def compute_membership_probs(data, means, sigmas, probs):
    """
    Compute the probability of each data example coming from each Gaussian in the Gaussian mixture model (GMM)

    :param data: d x n matrix of n d-dimensional data points. Each column is an example.
    :type data: ndarray
    :param means: d x num_clusters matrix where each column is one of the Gaussian means
    :type means: ndarray
    :param sigmas: list of num_clusters covariance matrices (each of shape (d, d))
    :type sigmas: list
    :param probs: vector of length num_clusters of the prior probability of each cluster generating data
    :type probs: arraylike
    :return: matrix of shape (num_clusters, n) where the (i, j)th entry is the probability that example j was
    generated by Gaussian i
    :rtype: ndarray
    """
    d, n = data.shape

    num_clusters = probs.size
    membership = np.zeros((num_clusters ,n))
    #print("means",means.shape)  # (d, num_cluster)
    #print("data",data.shape)    # (d, n)
    #print("prob",probs.shape)         # (num_cluster, )
    #print("sigmas",sigmas)      # array((d, d), num_clusters)
    ##############################################################
    # Insert your code to update cluster membership probabilities
    # for each data point

    gaussian_log_pdf = np.zeros((num_clusters, n))
    for i in range (0, num_clusters):   # Loop through num_clusters to complete gaussian_pdf
        #print("means[:, i]\n", means[:, i], means[:, i].shape)
        #print("sigmas[i]\n", sigmas[i], sigmas[i].shape)
        gaussian_log_pdf_i = gaussian_ll(data, means[:,i], sigmas[i]).reshape((1, n))
        gaussian_log_pdf[i,:] = gaussian_log_pdf_i.reshape((1, n))
    #print("gaussian_log_pdf", gaussian_log_pdf, gaussian_log_pdf.shape)

    probs_log = np.log(probs).reshape(num_clusters, 1)
    numerator_log = probs_log + gaussian_log_pdf
    denominator_log = logsumexp(numerator_log, dim=0)
    membership = numerator_log - denominator_log

    #print("membership\n", membership.shape)
    ##############################################################

    return membership


def gmm_ll(data, means, sigma, probs):
    """
    Compute the overall log-likelihood of data given a Gaussian mixture model.

    :param data: d x n matrix of n d-dimensional data points. Each column is an example.
    :type data: ndarray
    :param means: d x num_clusters matrix where each column is one of the Gaussian means
    :type means: ndarray
    :param sigma: list of num_clusters covariance matrices (each of shape (d, d))
    :type sigma: list
    :param probs: vector of length num_clusters of the prior probability of each cluster generating data
    :type probs: arraylike
    :return: the log-likelihood of all the data marginalizing out the cluster memberships
    :rtype: float
    """
    # The formula should be \prod_i \sum_k p(k) p(x_i | k)
    # The log of that is \sum_i \log(sum_k p(k) p(x_i | k))
    # p(x_i | k) should come from gaussian_ll
    num_clusters = probs.size

    d, n = data.shape

    ################################################################
    # Insert your code to compute the log-likelihood. You may
    # compute this using a loop over num_clusters, but you must not
    # loop over n. Use logsumexp to avoid numerical imprecision.
    ################################################################
    gaussian_log_pdf = np.zeros((num_clusters, n))
    for i in range (0, num_clusters):   # Loop through num_clusters to complete gaussian_pdf
        gaussian_log_pdf_i = gaussian_ll(data, means[:,i], sigma[i]).reshape((1, n))
        gaussian_log_pdf[i,:] = gaussian_log_pdf_i.reshape((1, n))

    probs_log = np.log(probs.reshape(num_clusters, 1))  # (num_clusters, 1)

    inner_log = np.add(gaussian_log_pdf, probs_log)
    ll_datai = logsumexp(inner_log, dim=0)
    ll = np.sum(ll_datai)





    return ll


def gaussian_ll(data, mean, sigma):
    """
    Compute the log-likelihoods of data points for a single Gaussian (parameterized by a mean and a covariance matrix).

    :param data: d x n matrix of n d-dimensional data points. Each column is an example.
    :type data: ndarray
    :param mean: length-d vector mean 2
    :type mean: arraylike
    :param sigma: shape (d, d) covariance matrix
    :type sigma: ndarray
    :return: length-n array of log-likelihoods
    :rtype: arraylike
    """

    return multivariate_normal.logpdf(data.T, mean=mean, cov=sigma)


def sample_gaussian(mean, sigma, n):
    """
    Sample from a multivariate Gaussian (parameterized by a mean and a covariance matrix).
    :param mean: length-d vector mean
    :type mean: arraylike
    :param sigma: shape (d, d) covariance matrix
    :type sigma: ndarray
    :param n: number of samples to generate
    :type n: int
    :return: d x n matrix where each column is a generated sample
    :rtype: ndarray
    """
    samples = multivariate_normal.rvs(mean=mean, cov=sigma, size=n).T

    if n == 1:
        samples = samples.reshape((-1, 1))

    return samples


def plot_gmm(data, means, sigmas, probs):
    """
    Plot a two-dimensional Gaussian mixture model.

    :param data: d x n matrix of n d-dimensional data points. Each column is an example.
    :type data: ndarray
    :param means: d x num_clusters matrix where each column is one of the Gaussian means
    :type means: ndarray
    :param sigmas: list of num_clusters covariance matrices (each of shape (d, d))
    :type sigmas: list
    :param probs: vector of length num_clusters of the prior probability of each cluster generating data
    :type probs: arraylike
    :return: None
    """
    d, k = means.shape
    num_clusters = probs.size

    resolution = 50

    angles = np.linspace(0, 2 * np.pi, resolution)

    x = [np.cos(angles), np.sin(angles)]

    for i in range(k):
        a = 2 * np.linalg.cholesky(sigmas[i])

        ellipse = a.dot(x) + means[:, i].reshape((-1, 1))
        plt.plot(ellipse[0, :], ellipse[1, :], 'r:')

    memberships = compute_membership_probs(data, means, sigmas, probs).argmax(0)
    plot_k_means(data, means, memberships)

    plt.title("GMM with %d Gaussians" % num_clusters)


def plot_k_means(data, means, memberships):
    """
    Plot clustered data
    :param data: d x n matrix of n d-dimensional data points. Each column is an example.
    :type data: ndarray
    :param means: d x num_clusters matrix where each column is one of the Gaussian means
    :type means: ndarray
    :param memberships: array of cluster-membership indices (each entry is an integer from 0 to num_clusters)
    :type memberships: arraylike
    :return: None
    """
    num_clusters = len(np.unique(memberships))

    for i in range(num_clusters):
        members = memberships == i
        plt.plot(data[0, members], data[1, members], 'xC%d' % i)

    plt.plot(means[0, :], means[1, :], 'ok')


def logsumexp(matrix, dim=None):
    """
    Compute log(np.sum(np.exp(matrix), dim)) in a numerically stable way.

    :param matrix: input ndarray
    :type matrix: ndarray
    :param dim: integer indicating which dimension to sum along
    :type dim: int
    :return: numerically stable equivalent of np.log(np.sum(np.exp(matrix), dim)))
    :rtype: ndarray
    """
    max_val = np.nan_to_num(matrix.max(axis=dim, keepdims=True))
    with np.errstate(under='ignore', divide='ignore'):
        return np.log(np.sum(np.exp(matrix - max_val), dim, keepdims=True)) + max_val
