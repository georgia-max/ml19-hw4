"""Functions for fitting Gaussian mixture models"""
from __future__ import division
import numpy as np
import pylab as plt
from scipy.stats import multivariate_normal


def gmm(data, num_clusters, plot=False):
    """
    Compute the cluster probabilities, means, and covariances of a Gaussian mixture model
    :param data: d x n matrix of n d-dimensional data points
    :type data: ndarray
    :param num_clusters: number of Gaussians to fit
    :type num_clusters: int
    :param plot: mode for plotting two-dimensional data. Can be False (no plotting), 'iter' (plot every iteration), or
    'final' (plot the final Gaussians).
    :return: tuple of (means, sigma, probs), where means is a d x num_clusters matrix, sigma is a list of num_clusters
    matrices of size d by d, and probs is a length-k vector of cluster-membership probabilities
    :rtype: tuple
    """
    d, n = data.shape

    # initialize clusters

    mu = np.mean(data, 1)
    centered_data = data - mu.reshape([-1, 1])
    full_sigma = np.inner(centered_data, centered_data) / n

    means = sample_gaussian(mu, full_sigma, num_clusters)

    sigmas = []

    for i in range(num_clusters):
        sigmas.append(np.eye(d))

    probs = np.ones(num_clusters) / num_clusters

    # start outer loop

    max_iters = 1000
    tolerance = 1e-4

    prev_probs = 0

    # add this to covariance matrices to prevent them from getting too skinny
    reg = 1e-4 * np.eye(d)

    for i in range(max_iters):
        membership = compute_membership_probs(data, means, sigmas, probs)

        ###################################################################
        # Insert your code to update cluster prior, means, and covariances
        # (probs, means, sigma)
        ###################################################################

        ##################################################################
        # End of code to compute probs, means, and sigma
        ##################################################################

        # plot GMM

        if d == 2 and plot is 'iter':
            plot_gmm(data, means, sigmas, probs)
            plt.pause(1.0 / 30.0)
            plt.clf()

        # check for convergence

        change = np.linalg.norm(prev_probs - probs)
        prev_probs = probs
        if change < tolerance:
            break

    if d == 2 and plot is 'final' or plot is 'iter':
        plot_gmm(data, means, sigmas, probs)

    return means, sigmas, probs


def compute_membership_probs(data, means, sigmas, probs):
    """
    Compute the probability of each data example coming from each Gaussian in the Gaussian mixture model (GMM)

    :param data: d x n matrix of n d-dimensional data points. Each column is an example.
    :type data: ndarray
    :param means: d x num_clusters matrix where each column is one of the Gaussian means
    :type means: ndarray
    :param sigmas: list of num_clusters covariance matrices (each of shape (d, d))
    :type sigmas: list
    :param probs: vector of length num_clusters of the prior probability of each cluster generating data
    :type probs: arraylike
    :return: matrix of shape (num_clusters, n) where the (i, j)th entry is the probability that example j was
    generated by Gaussian i
    :rtype: ndarray
    """
    d, n = data.shape

    num_clusters = probs.size

    membership = np.zeros((num_clusters, n))

    ##############################################################
    # Insert your code to update cluster membership probabilities
    # for each data point
    ##############################################################


    return membership


def gmm_ll(data, means, sigma, probs):
    """
    Compute the overall log-likelihood of data given a Gaussian mixture model.

    :param data: d x n matrix of n d-dimensional data points. Each column is an example.
    :type data: ndarray
    :param means: d x num_clusters matrix where each column is one of the Gaussian means
    :type means: ndarray
    :param sigma: list of num_clusters covariance matrices (each of shape (d, d))
    :type sigma: list
    :param probs: vector of length num_clusters of the prior probability of each cluster generating data
    :type probs: arraylike
    :return: the log-likelihood of all the data marginalizing out the cluster memberships
    :rtype: float
    """
    # The formula should be \prod_i \sum_k p(k) p(x_i | k)
    # The log of that is \sum_i \log(sum_k p(k) p(x_i | k))
    # p(x_i | k) should come from gaussian_ll
    num_clusters = probs.size

    d, n = data.shape

    ################################################################
    # Insert your code to compute the log-likelihood. You may
    # compute this using a loop over num_clusters, but you must not
    # loop over n. Use logsumexp to avoid numerical imprecision.
    ################################################################

    return ll


def gaussian_ll(data, mean, sigma):
    """
    Compute the log-likelihoods of data points for a single Gaussian (parameterized by a mean and a covariance matrix).

    :param data: d x n matrix of n d-dimensional data points. Each column is an example.
    :type data: ndarray
    :param mean: length-d vector mean
    :type mean: arraylike
    :param sigma: shape (d, d) covariance matrix
    :type sigma: ndarray
    :return: length-n array of log-likelihoods
    :rtype: arraylike
    """

    return multivariate_normal.logpdf(data.T, mean=mean, cov=sigma)


def sample_gaussian(mean, sigma, n):
    """
    Sample from a multivariate Gaussian (parameterized by a mean and a covariance matrix).
    :param mean: length-d vector mean
    :type mean: arraylike
    :param sigma: shape (d, d) covariance matrix
    :type sigma: ndarray
    :param n: number of samples to generate
    :type n: int
    :return: d x n matrix where each column is a generated sample
    :rtype: ndarray
    """
    samples = multivariate_normal.rvs(mean=mean, cov=sigma, size=n).T

    if n == 1:
        samples = samples.reshape((-1, 1))

    return samples


def plot_gmm(data, means, sigmas, probs):
    """
    Plot a two-dimensional Gaussian mixture model.

    :param data: d x n matrix of n d-dimensional data points. Each column is an example.
    :type data: ndarray
    :param means: d x num_clusters matrix where each column is one of the Gaussian means
    :type means: ndarray
    :param sigmas: list of num_clusters covariance matrices (each of shape (d, d))
    :type sigmas: list
    :param probs: vector of length num_clusters of the prior probability of each cluster generating data
    :type probs: arraylike
    :return: None
    """
    d, k = means.shape
    num_clusters = probs.size

    resolution = 50

    angles = np.linspace(0, 2 * np.pi, resolution)

    x = [np.cos(angles), np.sin(angles)]

    for i in range(k):
        a = 2 * np.linalg.cholesky(sigmas[i])

        ellipse = a.dot(x) + means[:, i].reshape((-1, 1))
        plt.plot(ellipse[0, :], ellipse[1, :], 'r:')

    memberships = compute_membership_probs(data, means, sigmas, probs).argmax(0)
    plot_k_means(data, means, memberships)

    plt.title("GMM with %d Gaussians" % num_clusters)


def plot_k_means(data, means, memberships):
    """
    Plot clustered data
    :param data: d x n matrix of n d-dimensional data points. Each column is an example.
    :type data: ndarray
    :param means: d x num_clusters matrix where each column is one of the Gaussian means
    :type means: ndarray
    :param memberships: array of cluster-membership indices (each entry is an integer from 0 to num_clusters)
    :type memberships: arraylike
    :return: None
    """
    num_clusters = len(np.unique(memberships))

    for i in range(num_clusters):
        members = memberships == i
        plt.plot(data[0, members], data[1, members], 'xC%d' % i)

    plt.plot(means[0, :], means[1, :], 'ok')


def logsumexp(matrix, dim=None):
    """
    Compute log(np.sum(np.exp(matrix), dim)) in a numerically stable way.

    :param matrix: input ndarray
    :type matrix: ndarray
    :param dim: integer indicating which dimension to sum along
    :type dim: int
    :return: numerically stable equivalent of np.log(np.sum(np.exp(matrix), dim)))
    :rtype: ndarray
    """
    try:
        with np.errstate(over='raise', under='raise'):
            return np.log(np.sum(np.exp(matrix), dim, keepdims=True))
    except FloatingPointError:
        max_val = np.nan_to_num(matrix.max(axis=dim, keepdims=True))
        with np.errstate(under='ignore', divide='ignore'):
            return np.log(np.sum(np.exp(matrix - max_val), dim, keepdims=True)) + max_val
